{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from hyperopt import fmin, tpe, space_eval, Trials, hp, rand, anneal\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 생성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **add_features( )** : 주가데이터가 담긴 데이터프레임에 원하는 window 크기의 feature를 생성하는 함수\n",
    "- **labeling( )** : n일 이동평균 대비 m일 후 m일 이동평균 상승 여부에 따라 라벨링\n",
    "- **feature_scaling( )** : 주어진 feature에 대해 스케일링을 진행\n",
    "- **make_data( )** : 데이터 생성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `MA_5` : 5일 이동평균  \n",
    "- `STD` : n일 종가의 표준편차\n",
    "- `Upper`, `Lower` : MA_5에서 2 * STD의 값을 더하고 빼준 구간\n",
    "- `Out` : 당일 종가가 Upper, Lower 벗어난 경우 각각 1, -1\n",
    "- `MA` : n일 이동평균\n",
    "- `OBV` : 거래량의 누적치, 주가가 오르면 더해주고, 내리면 빼줌\n",
    "- `CCI` : 주가와 이동평균 차이를 측정하여 구한 모멘텀 지표\n",
    "- `fast_k` (스토캐스틱) : n일 동안의 최저, 최고가 범위에서 현재 종가의 위치\n",
    "- `fask_d` : fask_k의 n일 이동평균\n",
    "- `ROC` : n일 전 종가 대비 현재 종가 변화율\n",
    "- `RSI` (상대강도지수) : n일 동안의 종가 상승 / 하락 평균을 이용한 모멘텀 지표\n",
    "- `MFI` : 가격과 거래량을 모두 반영한 모멘텀 지표\n",
    "- `ks_fast` : 코스피 데이터에 반영한 fask_k\n",
    "- `ks_ROC` : 코스피 데이터에 반영한 ROC\n",
    "- `DP` : n일 종가 이동평균 대비 당일종가 (-1~1 범위 갖도록 값에 1 빼서 사용) (=이격도-1)\n",
    "- `RSI_DP` : RSI의 n일 이동평균 대비 현재 RSI\n",
    "- `ks_DP` : 코스피 지수의 DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_data = pd.read_csv('./Stock_price/stock_data.csv')\n",
    "# 코스피 데이터 생성\n",
    "ks11 = fdr.DataReader('KS11', '2012-06-01')\n",
    "ks11['ks_fast'] = ((ks11['Close'] - ks11['Low'].rolling(14).min()) / (ks11['High'].rolling(14).max() - ks11['Low'].rolling(14).min())) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "def adf_test(timeseries):\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries, autolag=\"AIC\")\n",
    "    dfoutput = pd.Series(\n",
    "        dftest[0:4],\n",
    "        index=[\n",
    "            \"Test Statistic\",\n",
    "            \"p-value\",\n",
    "            \"#Lags Used\",\n",
    "            \"Number of Observations Used\",\n",
    "        ],\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[\"Critical Value (%s)\" % key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "def kpss_test(timeseries):\n",
    "    print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "    print(kpss_output)\n",
    "\n",
    "def adf_kpss_test_for_cols(df, columns):\n",
    "    print('분석 대상 :', df['Code'].values[0])\n",
    "    for col in columns:\n",
    "        print(\"--------------------{0:^10}---------------------\".format(col))\n",
    "        adfuller_test = adfuller(df[col], autolag= \"AIC\")\n",
    "        print(\"ADF test statistic: {}\".format(adfuller_test[0]))\n",
    "        print(\"p-value: {}\".format(adfuller_test[1]))\n",
    "        kpsstest = kpss(df[col], regression=\"c\", nlags=\"auto\")\n",
    "        print(\"KPSS test statistic: {}\".format(kpsstest[0]))\n",
    "        print(\"p-value: {}\".format(kpsstest[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5일 이동평균\n",
    "def add_ma_5(df):\n",
    "    df['MA_5'] = df['Close'].rolling(window=5).mean().values\n",
    "    return\n",
    "\n",
    "# 볼린저 밴드\n",
    "def add_bollinger_bands(df, window=20, std=2):\n",
    "    # 표준편차 계산\n",
    "    df['STD'] = df['Close'].rolling(window=window).std()\n",
    "    # 상단 볼린저 밴드 계산\n",
    "    df['Upper'] = df['MA_5'] + (std * df['STD'])\n",
    "    # 하단 볼린저 밴드 계산\n",
    "    df['Lower'] = df['MA_5'] - (std * df['STD'])\n",
    "    return\n",
    "\n",
    "def add_Out(df):\n",
    "    df['Out'] = ((df['Upper'] - df['Close'] < 0) + 0) + -((df['Lower'] > df['Close']) + 0)\n",
    "    return\n",
    "\n",
    "# 이동평균\n",
    "def add_moving_avg(df, window=5):\n",
    "    df['MA'] = df['Close'].rolling(window=window).mean().values\n",
    "    return\n",
    "\n",
    "# 거래량 관련\n",
    "def add_obv(df):\n",
    "    obv = [0]\n",
    "    for i in range(1, len(df)):\n",
    "        if df['Close'][i] > df['Close'][i-1]:\n",
    "            obv.append(obv[-1] + df['Volume'][i])\n",
    "        elif df['Close'][i] < df['Close'][i-1]:\n",
    "            obv.append(obv[-1] - df['Volume'][i])\n",
    "        else:\n",
    "            obv.append(obv[-1])\n",
    "    df['OBV'] = obv\n",
    "    return\n",
    "\n",
    "def add_cci(df, window=20):\n",
    "    m = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "    n = m.rolling(window).mean()\n",
    "    # d = (abs(m - n)).rolling(window).mean()\n",
    "    d = m.rolling(window).apply(lambda x: pd.Series(x).sub(x.mean()).abs().mean())\n",
    "    # d = m.rolling(window).apply(lambda x : pd.Series(x).mad())\n",
    "    df['CCI'] = (m - n) / (0.015 * d)\n",
    "    return\n",
    "\n",
    "def add_stochastic_fast_k(df, window=14):\n",
    "    df['fast_k'] = ((df['Close'] - df['Low'].rolling(window).min()) / (df['High'].rolling(window).max() - df['Low'].rolling(window).min())) * 100\n",
    "    return\n",
    "\n",
    "def add_stochastic_fast_d(df, window=9):\n",
    "    df['fast_d'] = df['fast_k'].rolling(window=window).mean().values\n",
    "    return\n",
    "\n",
    "def add_ROC(df, window=1):\n",
    "    df['ROC'] = df.Close.diff(window) / df.Close.shift(window)\n",
    "    return\n",
    "\n",
    "def add_RSI(df, period=14):\n",
    "    delta = df[\"Close\"].diff() # 종가의 차이를 계산\n",
    "    up, down = delta.copy(), delta.copy() # 상승분과 하락분을 따로 계산하기 위해 복사\n",
    "    up[up < 0] = 0 # 상승분, U\n",
    "    down[down > 0] = 0 # 하락분, D\n",
    "    _gain = up.ewm(com=(period - 1), min_periods=period).mean() # AU(U값의 평균)\n",
    "    _loss = down.abs().ewm(com=(period - 1), min_periods=period).mean() # DU(D값의 평균)\n",
    "    RS = _gain / _loss\n",
    "    rsi = pd.Series(100 - (100 / (1 + RS)), name=\"RSI\")\n",
    "    df['RSI'] = rsi\n",
    "    return\n",
    "\n",
    "def add_RSI_DP(df, window=2):\n",
    "    df['RSI_DP'] = np.round(df['RSI'] / df['RSI'].rolling(window=window).mean(), 4) - 1\n",
    "    return\n",
    "\n",
    "def add_DP(df, window=20):\n",
    "    df['DP'] = np.round(df['Close'] / df['Close'].rolling(window=window).mean(), 4) - 1\n",
    "    return\n",
    "\n",
    "def add_MFI(df, period = 14): \n",
    "\t# 우선적으로 각 기간에 맞게 평균 가격(TP)을 구합니다. \n",
    "    typical_price = (df['High'] + df['Low'] + df['Close']) / 3  # TP\n",
    "    money_flow = typical_price * df['Volume']\n",
    "    positive_flow =[] \n",
    "    negative_flow = []\n",
    "    \n",
    "    # 반복문을 돌면서 기간별 양의 RMF, 음의 RMF를 구현합니다.\n",
    "    # Loop through the typical price \n",
    "    for i in range(1, len(typical_price)):\n",
    "        if typical_price[i] > typical_price[i-1]: \n",
    "            positive_flow.append(money_flow[i-1])\n",
    "            negative_flow.append(0) \n",
    "        elif typical_price[i] < typical_price[i-1]:\n",
    "            negative_flow.append(money_flow[i-1])\n",
    "            positive_flow.append(0)\n",
    "        else: \n",
    "            positive_flow.append(0)\n",
    "            negative_flow.append(0)\n",
    "    \n",
    "    positive_mf = []\n",
    "    negative_mf = [] \n",
    "    # 기간동안 평균 가격들의 분류가 끝난 경우, RMF 계산식을 이용해 평균 가격과 당일 거래량을 곱합니다. \n",
    "    # Get all of the positive money flows within the time period\n",
    "    for i in range(period-1, len(positive_flow)):\n",
    "        positive_mf.append(sum(positive_flow[i+1-period : i+1]))\n",
    "    # Get all of the negative money flows within the time period  \n",
    "    for i in range(period-1, len(negative_flow)):\n",
    "        negative_mf.append(sum(negative_flow[i+1-period : i+1]))\n",
    "    # for i in range(len(positive_mf)):\n",
    "    #     if positive_mf[i] == 0 and negative_mf[i] == 0:\n",
    "    #         negative_mf[i] = 1\n",
    "    # MFR을 계산합니다. 그 후 MFI를 구합니다. \n",
    "    mfi = list(100 * (np.array(positive_mf) / (np.array(positive_mf)  + np.array(negative_mf))))\n",
    "    mfi = list(np.repeat(np.nan,len(df)-len(mfi))) + mfi\n",
    "    df['MFI'] = mfi\n",
    "    return\n",
    "\n",
    "# 종목 데이터에 코스피 데이터를 날짜 기준으로 병합\n",
    "def add_ks_data(df, ks11, window=1):\n",
    "    # df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    ks11['ks_ROC'] = np.round(ks11.Close.diff(window) / ks11.Close.shift(window), 4)\n",
    "    ks11['ks_DP'] = np.round(ks11.Close / ks11.Close.rolling(window=window).mean().values, 4) - 1\n",
    "    data = pd.merge(df, ks11[['ks_ROC', 'ks_DP', 'ks_fast']], left_on='Date', right_index=True)\n",
    "    return data\n",
    "\n",
    "def labeling(data, a_window=5, b_window=5):\n",
    "    a_name = 'MA_'+str(a_window)\n",
    "    b_name = 'MA_'+str(b_window)\n",
    "    data[a_name] = data['Close'].rolling(window=a_window).mean().values\n",
    "    data[b_name] = data['Close'].rolling(window=b_window).mean().values\n",
    "    data['label'] = None\n",
    "    for i in range(len(data)-b_window):\n",
    "        data.loc[i, 'label'] = 1 if data.loc[i, a_name] <= data.loc[i+b_window, b_name] else 0\n",
    "    return\n",
    "\n",
    "def add_FROC(df):\n",
    "    df['FROC_60'] = df.Close.shift(-60) / df.Close - 1\n",
    "    df['FROC_30'] = df.Close.shift(-30) / df.Close - 1\n",
    "    df['FROC_10'] = df.Close.shift(-10) / df.Close - 1\n",
    "    df['FROC_5'] = df.Close.shift(-5) / df.Close - 1\n",
    "    return\n",
    "\n",
    "def add_features(df, window_params, label_window):\n",
    "    df['Date'] = df.index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    add_ma_5(df)\n",
    "    add_bollinger_bands(df)\n",
    "    add_Out(df)\n",
    "    add_obv(df)\n",
    "    # add_moving_avg(df, window=int(window_params['MA']))\n",
    "    add_cci(df, window=int(window_params['CCI']))\n",
    "    add_stochastic_fast_k(df, window=int(window_params['fast_k']))\n",
    "    add_stochastic_fast_d(df, window=int(window_params['fast_d']))\n",
    "    add_ROC(df, window=int(window_params['ROC']))\n",
    "    add_RSI(df, int(window_params['RSI']))\n",
    "    add_RSI_DP(df, int(window_params['RSI_DP']))\n",
    "    add_MFI(df, int(window_params['MFI']))\n",
    "    add_DP(df, int(window_params['DP']))\n",
    "    add_FROC(df)\n",
    "    labeling(df, *label_window)\n",
    "\n",
    "    # df.dropna(axis=0, inplace=True)\n",
    "    # df.reset_index(drop=True, inplace=True)\n",
    "    return\n",
    "\n",
    "def feature_scaling(df, scaling_features):\n",
    "    rbc = RobustScaler()\n",
    "    mmc = MinMaxScaler()\n",
    "    df[scaling_features['rbc']] = rbc.fit_transform(df[scaling_features['rbc']])\n",
    "    df[scaling_features['mmc']] = mmc.fit_transform(df[scaling_features['mmc']])\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **make_data**( )\n",
    "- *stock_dict* : 종목코드가 담긴 dictionary\n",
    "- *window_params* : feature의 window 크기 설정\n",
    "- *date_range* : 분석 기간 설정\n",
    "- *label_window* : 라벨링 window 크기 설정\n",
    "- *scaling_features* : model_features가 설정된 경우 스케일링 필요한 feature를 rbc, mmc 나누어 입력 시 스케일링 진행\n",
    "- *model_features* : 모델 학습에 사용할 feature list 입력 시 train_X, val_X, test_X, train_y, val_y, test_y를 return, 설정 안할 시 분할되지 않은 data return\n",
    "- *sta_test* : 학습데이터가 아닌 일반데이터 생성 시 True 값 주어 feature의 정상성 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(stock_dict, window_params, date_range, label_window, scaling_features=None, model_features=None, test_features=None):\n",
    "    data = pd.DataFrame()\n",
    "    val_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "    scaled_data = pd.DataFrame()\n",
    "    scaled_val_data = pd.DataFrame()\n",
    "    scaled_test_data = pd.DataFrame()\n",
    "    # 종목 코드에 대해 데이터를 생성해 data, val_data, test_data에 합치기\n",
    "    for name, code in stock_dict.items():\n",
    "        # 종목 코드, 정한 기간에 대한 주가 데이터\n",
    "        df = fdr.DataReader(code, *date_range)\n",
    "        df = df.loc[~(df[['Open', 'High', 'Low', 'Close', 'Volume']] == 0).any(axis=1)]\n",
    "        df['company_name'] = name\n",
    "        df['Code'] = code\n",
    "        # 입력한 윈도우 크기를 사용하여 주가 데이터 기반으로 여러 지표를 생성, 정해둔 방식으로 라벨링\n",
    "        add_features(df, window_params=window_params, label_window=label_window)\n",
    "        # 데이터에 코스피 데이터 날짜 기준으로 병합\n",
    "        df = add_ks_data(df, ks11, window=int(window_params['ks_ROC']))\n",
    "        # 널값 제거\n",
    "        # print(df.isnull().sum())\n",
    "        df.dropna(axis=0, inplace=True)\n",
    "        # 라벨 타입 변경\n",
    "        df['label'] = df['label'].astype(int)\n",
    "        # 분석기간부터의 데이터만 남김\n",
    "        df = df[df.Date >= date_range[0]]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # 데이터 검증 True인 경우 -> 데이터 정상성 검증\n",
    "        if test_features:\n",
    "            adf_kpss_test_for_cols(df, test_features)\n",
    "        \n",
    "        # 모델 학습에 사용할 지표가 지정된 경우 -> data, test_data에 기간을 나누어 합침\n",
    "        if model_features:\n",
    "            train_length = int(len(df)*0.7)\n",
    "            val_length = int(len(df)*0.85)\n",
    "\n",
    "            train_df = df.loc[:train_length, :].copy()\n",
    "            val_df = df.loc[train_length+1:val_length, :].copy()\n",
    "            test_df = df.loc[val_length+1:, :].copy()\n",
    "            \n",
    "            # train_length = int(len(df)*0.3)\n",
    "            # val_length = int(len(df)*0.15)\n",
    "\n",
    "            # train_df = df.loc[train_length:, :].copy()\n",
    "            # val_df = df.loc[val_length+1:train_length-1, :].copy()\n",
    "            # test_df = df.loc[:val_length, :].copy()\n",
    "\n",
    "            data = pd.concat([data, train_df], axis=0)\n",
    "            val_data = pd.concat([val_data, val_df], axis=0)\n",
    "            test_data = pd.concat([test_data, test_df], axis=0)\n",
    "\n",
    "            # 스케일링 대상 feature가 지정된 경우 -> 대상에 대해 스케일링 진행\n",
    "            if scaling_features:\n",
    "                rbc = RobustScaler()\n",
    "                mmc = MinMaxScaler()\n",
    "\n",
    "                if len(train_df[scaling_features['rbc']])==0:\n",
    "                    print(df)\n",
    "                    print(train_length, val_length, len(df))\n",
    "                    print('train')\n",
    "                if len(val_df[scaling_features['rbc']])==0:\n",
    "                    print('val')\n",
    "                if len(test_df[scaling_features['rbc']])==0:\n",
    "                    print('test')\n",
    "                \n",
    "                train_df[scaling_features['rbc']] = rbc.fit_transform(train_df[scaling_features['rbc']])\n",
    "                val_df[scaling_features['rbc']] = rbc.transform(val_df[scaling_features['rbc']])\n",
    "                test_df[scaling_features['rbc']] = rbc.transform(test_df[scaling_features['rbc']])\n",
    "\n",
    "                train_df[scaling_features['mmc']] = mmc.fit_transform(train_df[scaling_features['mmc']])\n",
    "                val_df[scaling_features['mmc']] = mmc.transform(val_df[scaling_features['mmc']])\n",
    "                test_df[scaling_features['mmc']] = mmc.transform(test_df[scaling_features['mmc']])\n",
    "\n",
    "                scaled_data = pd.concat([scaled_data, train_df], axis=0)\n",
    "                scaled_val_data = pd.concat([scaled_val_data, val_df], axis=0)\n",
    "                scaled_test_data = pd.concat([scaled_test_data, test_df], axis=0)\n",
    "                pass\n",
    "            continue\n",
    "        # model_features=None인 경우 하나의 DateFrame에 합쳐서 return\n",
    "        data = pd.concat([data, df], axis=0)\n",
    "    \n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    # model_features가 지정된 경우 데이터를 split하여 return\n",
    "    if model_features and scaling_features:\n",
    "        original_data = pd.concat([data, val_data, test_data], axis=0)\n",
    "        original_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        scaled_data.reset_index(drop=True, inplace=True)\n",
    "        scaled_val_data.reset_index(drop=True, inplace=True)\n",
    "        scaled_test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        train_X = scaled_data[model_features].values\n",
    "        val_X = scaled_val_data[model_features].values\n",
    "        test_X = scaled_test_data[model_features].values\n",
    "\n",
    "        train_y = scaled_data['label'].values\n",
    "        val_y = scaled_val_data['label'].values\n",
    "        test_y = scaled_test_data['label'].values\n",
    "        return original_data, train_X, val_X, test_X, train_y, val_y, test_y\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_data 입력값 예시\n",
    "\n",
    "# 종목 이름과 코드 정보가 담긴 dictionary\n",
    "stock_dict = {\n",
    "    '포스코': '005490',\n",
    "    '삼성전자': '005930',\n",
    "    '현대차': '005380',\n",
    "    '셀트리온': '068270',\n",
    "    '삼성생명': '032830'\n",
    "}\n",
    "\n",
    "# 각 지표의 window 크기를 지정하는 dictionary\n",
    "window_params = {\n",
    "    'MA' : 5, \n",
    "    'CCI' : 20,\n",
    "    'fast_k' : 14, \n",
    "    'fast_d' : 9, \n",
    "    'ROC' : 5, \n",
    "    'ks_ROC' : 5,\n",
    "    'RSI' : 14,\n",
    "    'MFI' : 14\n",
    "}\n",
    "\n",
    "# 라벨링 윈도우 크기 지정 -> 5일 이동평균과 20일 이후 20일 이동평균을 비교\n",
    "label_window = (5, 20)\n",
    "\n",
    "# 분석 대상 기간 설정\n",
    "date_range = ['2017-01-01', '2023-05-31']\n",
    "\n",
    "# 스케일링 필요시 시정 -> rbc, mmc 나누어 지정\n",
    "scaling_features = {'rbc' : ['Volume', 'Change', 'ROC', 'ks_ROC'],\n",
    "                    'mmc' : ['Open', 'High', 'Low', 'Close', 'MA_5',\n",
    "                                'STD', 'Upper', 'Lower', 'OBV', 'MA', 'CCI', 'fast_k', 'fast_d',\n",
    "                                'RSI', 'MFI', 'MA_20', 'ks_fast']}\n",
    "\n",
    "# 모델 학습에 사용할 지표 지정 -> 지정 시 train, test split하여 return\n",
    "model_features = ['Volume', 'Change', 'ROC', 'ks_ROC', 'MA_5',\n",
    "                    'STD', 'Upper', 'Lower',\n",
    "                    'OBV', 'MA', 'CCI', 'fast_k', 'fast_d',\n",
    "                    'RSI', 'MFI', 'MA_20', 'ks_fast']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **objective**( ) : feature window, model parameter value가 담긴 params에 대해 데이터를 생성하여 XGBClassifier로 학습, 정확도의 음의 값 반환\n",
    "- **loss_objective**( ) : binary cross entropy 값 반환\n",
    "- **roc_objective**( ) : roc-auc 정확도의 음의 값 반환\n",
    "- **corr_objective**( ) : 10일 후 주가상승률, 30일 후 주가상승률 평균과의 상관계수 음의 값 반환\n",
    "\n",
    "- eval=True 설정 시 train, valid로 fit한 model, test_X, test_y를 반환"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fmin**(objective, space, algo=, max_evals=, trials=) : space에서 params를 생성, algo의 방법으로 max_evals 횟수만큼 시도하여 objective를 최소화하여 trials에 기록하는 함수\n",
    "    - tpe.suggest\n",
    "    - atpe.suggest\n",
    "    - rand.suggest\n",
    "    - anneal.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, eval=False):\n",
    "    # params에서 윈도우 크기 불러오기\n",
    "    window_params = {\n",
    "        'MA': int(params['MA']),\n",
    "        'CCI': int(params['CCI']),\n",
    "        'fast_k': int(params['fast_k']),\n",
    "        'fast_d': int(params['fast_d']),\n",
    "        'ROC': int(params['ROC']),\n",
    "        'ks_ROC': int(params['ks_ROC']),\n",
    "        'RSI': int(params['RSI']),\n",
    "        'MFI': int(params['MFI']),\n",
    "        'RSI_DP' : int(params['RSI_DP']),\n",
    "        'DP' : int(params['DP'])\n",
    "    }\n",
    "    \n",
    "    # 데이터셋 생성\n",
    "    original_data, train_X, val_X, test_X, train_y, val_y, test_y = make_data(stock_dict, window_params, date_range, label_window, scaling_features=scaling_features, model_features=model_features)\n",
    "    negative_rate = 1 - np.round(np.concatenate([train_y, val_y, test_y], axis=0).sum() / len(np.concatenate([train_y, val_y, test_y], axis=0)), 4)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = xgb.XGBClassifier(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=int(params['max_depth']),\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        gamma=params['gamma'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        scale_pos_weight=negative_rate,\n",
    "        random_state=0\n",
    "    )\n",
    "    model.fit(train_X, train_y)\n",
    "    y_pred = model.predict(val_X)\n",
    "    accuracy = accuracy_score(val_y, y_pred)\n",
    "\n",
    "    if eval:\n",
    "        model.fit(np.concatenate([train_X, val_X], axis=0), np.concatenate([train_y, val_y], axis=0))\n",
    "        print('train + valid 정확도', accuracy_score(np.concatenate([train_y, val_y], axis=0), model.predict(np.concatenate([train_X, val_X], axis=0))))\n",
    "        print('test          정확도', accuracy_score(test_y, model.predict(test_X)))\n",
    "        return model, original_data, train_X, val_X, test_X, train_y, val_y, test_y\n",
    "    return -accuracy\n",
    "\n",
    "def corr_objective(params, eval=False):\n",
    "    # params에서 윈도우 크기 불러오기\n",
    "    window_params = {\n",
    "        'MA': int(params['MA']),\n",
    "        'CCI': int(params['CCI']),\n",
    "        'fast_k': int(params['fast_k']),\n",
    "        'fast_d': int(params['fast_d']),\n",
    "        'ROC': int(params['ROC']),\n",
    "        'ks_ROC': int(params['ks_ROC']),\n",
    "        'RSI': int(params['RSI']),\n",
    "        'MFI': int(params['MFI']),\n",
    "        'RSI_DP' : int(params['RSI_DP']),\n",
    "        'DP' : int(params['DP'])\n",
    "    }\n",
    "    \n",
    "    # 데이터셋 생성\n",
    "    original_data, train_X, val_X, test_X, train_y, val_y, test_y = make_data(stock_dict, window_params, date_range, label_window, scaling_features=scaling_features, model_features=model_features)\n",
    "    negative_rate = 1 - np.round(np.concatenate([train_y, val_y, test_y], axis=0).sum() / len(np.concatenate([train_y, val_y, test_y], axis=0)), 4)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = xgb.XGBClassifier(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=int(params['max_depth']),\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        gamma=params['gamma'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        scale_pos_weight=negative_rate,\n",
    "        random_state=0\n",
    "    )\n",
    "    model.fit(train_X, train_y)\n",
    "    y_prob = model.predict_proba(val_X)[:, 1]\n",
    "    froc = np.mean(original_data.loc[len(train_y):len(train_y)+len(val_y)-1, ['FROC_10', 'FROC_30']].values, axis=1)\n",
    "    corr = np.corrcoef(y_prob, froc)[0, 1]\n",
    "    if eval:\n",
    "        model.fit(np.concatenate([train_X, val_X], axis=0), np.concatenate([train_y, val_y], axis=0))\n",
    "        print('train + valid 정확도', accuracy_score(np.concatenate([train_y, val_y], axis=0), model.predict(np.concatenate([train_X, val_X], axis=0))))\n",
    "        print('test          정확도', accuracy_score(test_y, model.predict(test_X)))\n",
    "        print(np.corrcoef(model.predict_proba(test_X)[:, 1], np.mean(original_data.loc[len(val_y)+len(train_y):, ['FROC_10', 'FROC_30']].values, axis=1))[0, 1])\n",
    "        return model, original_data, train_X, val_X, test_X, train_y, val_y, test_y\n",
    "    return -corr\n",
    "\n",
    "def loss_objective(params, eval=False):\n",
    "    # params에서 윈도우 크기 불러오기\n",
    "    window_params = {\n",
    "        'MA': int(params['MA']),\n",
    "        'CCI': int(params['CCI']),\n",
    "        'fast_k': int(params['fast_k']),\n",
    "        'fast_d': int(params['fast_d']),\n",
    "        'ROC': int(params['ROC']),\n",
    "        'ks_ROC': int(params['ks_ROC']),\n",
    "        'RSI': int(params['RSI']),\n",
    "        'MFI': int(params['MFI']),\n",
    "        'RSI_DP' : int(params['RSI_DP']),\n",
    "        'DP' : int(params['DP'])\n",
    "    }\n",
    "    \n",
    "    # 데이터셋 생성\n",
    "    original_data, train_X, val_X, test_X, train_y, val_y, test_y = make_data(stock_dict, window_params, date_range, label_window, scaling_features=scaling_features, model_features=model_features)\n",
    "    negative_rate = 1 - np.round(np.concatenate([train_y, val_y, test_y], axis=0).sum() / len(np.concatenate([train_y, val_y, test_y], axis=0)), 4)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = xgb.XGBClassifier(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=int(params['max_depth']),\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        gamma=params['gamma'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        scale_pos_weight=negative_rate,\n",
    "        random_state=0\n",
    "    )\n",
    "    model.fit(train_X, train_y)\n",
    "    proba = model.predict_proba(val_X)[:, 1]\n",
    "    loss = -np.mean(val_y * np.log(proba) + (1 - val_y) * np.log(1 - proba))\n",
    "\n",
    "    if eval:\n",
    "        model.fit(np.concatenate([train_X, val_X], axis=0), np.concatenate([train_y, val_y], axis=0))\n",
    "        print('train + valid 정확도', accuracy_score(np.concatenate([train_y, val_y], axis=0), model.predict(np.concatenate([train_X, val_X], axis=0))))\n",
    "        print('test          정확도', accuracy_score(test_y, model.predict(test_X)))\n",
    "        return model, original_data, train_X, val_X, test_X, train_y, val_y, test_y\n",
    "    return loss\n",
    "\n",
    "def roc_objective(params, eval=False):\n",
    "    # params에서 윈도우 크기 불러오기\n",
    "    window_params = {\n",
    "        'MA': int(params['MA']),\n",
    "        'CCI': int(params['CCI']),\n",
    "        'fast_k': int(params['fast_k']),\n",
    "        'fast_d': int(params['fast_d']),\n",
    "        'ROC': int(params['ROC']),\n",
    "        'ks_ROC': int(params['ks_ROC']),\n",
    "        'RSI': int(params['RSI']),\n",
    "        'MFI': int(params['MFI']),\n",
    "        'RSI_DP' : int(params['RSI_DP']),\n",
    "        'DP' : int(params['DP'])\n",
    "    }\n",
    "    \n",
    "    # 데이터셋 생성\n",
    "    original_data, train_X, val_X, test_X, train_y, val_y, test_y = make_data(stock_dict, window_params, date_range, label_window, scaling_features=scaling_features, model_features=model_features)\n",
    "    negative_rate = 1 - np.round(np.concatenate([train_y, val_y, test_y], axis=0).sum() / len(np.concatenate([train_y, val_y, test_y], axis=0)), 4)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = xgb.XGBClassifier(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=int(params['max_depth']),\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        gamma=params['gamma'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        scale_pos_weight=negative_rate,\n",
    "        random_state=0\n",
    "    )\n",
    "    model.fit(train_X, train_y)\n",
    "    proba = model.predict_proba(val_X)[:, 1]\n",
    "    test_fpr, test_tpr, _ = roc_curve(val_y, proba)\n",
    "\n",
    "    test_auc = auc(test_fpr, test_tpr)\n",
    "\n",
    "    if eval:\n",
    "        model.fit(np.concatenate([train_X, val_X], axis=0), np.concatenate([train_y, val_y], axis=0))\n",
    "        print('train + valid 정확도', accuracy_score(np.concatenate([train_y, val_y], axis=0), model.predict(np.concatenate([train_X, val_X], axis=0))))\n",
    "        print('test          정확도', accuracy_score(test_y, model.predict(test_X)))\n",
    "        return model, original_data, train_X, val_X, test_X, train_y, val_y, test_y\n",
    "    return -test_auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials에 사용된 parameter 값들의 분포 시각화\n",
    "con_params = ['learning_rate', 'gamma', 'reg_lambda', 'reg_alpha', 'subsample', 'colsample_bytree', 'n_estimators', ]\n",
    "int_params = ['max_depth', 'MA', 'CCI', 'fast_k', 'fast_d', 'ROC', 'ks_ROC', 'RSI', 'MFI']\n",
    "def param_distribute(trials):\n",
    "    # 정수형 하이퍼파라미터의 분포를 막대 그래프로 표현\n",
    "    for parameter in int_params:\n",
    "        parameter_values = trials.idxs_vals[1][parameter]\n",
    "        value_range = range(int(min(parameter_values)), int(max(parameter_values))+1)\n",
    "        parameter_counts = [parameter_values.count(i) for i in value_range]\n",
    "\n",
    "        plt.bar(value_range, parameter_counts)\n",
    "        plt.xlabel(parameter)\n",
    "        plt.ylabel('Counts')\n",
    "        plt.title('Distribution of '+parameter)\n",
    "        plt.show()\n",
    "\n",
    "    # 실수형 하이퍼파라미터의 분포를 히스토그램으로 표현\n",
    "    for parameter in con_params:\n",
    "        parameter_values = trials.idxs_vals[1][parameter]\n",
    "        plt.hist(parameter_values, bins=40)\n",
    "        plt.xlabel(parameter)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of '+parameter)\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "# 모델의 auc-roc 시각화\n",
    "def AUC_ROC(model, test_X, test_y):\n",
    "    test_y_pred_proba = model.predict_proba(test_X)[:, 1]  # 클래스 1의 예측 확률만 선택\n",
    "\n",
    "    test_fpr, test_tpr, _ = roc_curve(test_y, test_y_pred_proba)\n",
    "\n",
    "    test_auc = auc(test_fpr, test_tpr)\n",
    "    # print(train_auc, test_auc)\n",
    "    plt.figure()\n",
    "    plt.plot(test_fpr, test_tpr, color='navy', lw=2, label='Test ROC curve (AUC = %0.2f)' % test_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def show_imp(xgb_model):\n",
    "    fig, ax = plt.subplots(figsize = (10, 6))\n",
    "    plot_importance(xgb_model, ax = ax)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 50, 1000, 1),\n",
    "        'gamma': hp.uniform('gamma', 0, 10),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0, 10),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0, 10),\n",
    "        'subsample': hp.uniform('subsample', 0, 1),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0, 1),\n",
    "        'MA' : hp.quniform('MA', 1, 24, 1),\n",
    "        'CCI' : hp.quniform('CCI', 10, 90, 5),\n",
    "        'fast_k' : hp.quniform('fast_k', 3, 30, 1),\n",
    "        'fast_d' : hp.quniform('fast_d', 3, 14, 1),\n",
    "        'ROC' : hp.quniform('ROC', 3, 60, 2),\n",
    "        'ks_ROC' : hp.quniform('ks_ROC', 3, 60, 2),\n",
    "        'RSI' : hp.quniform('RSI', 2, 15, 2),\n",
    "        'MFI' : hp.quniform('MFI', 2, 15, 2)\n",
    "}\n",
    "label_window = (5, 10)\n",
    "date_range = ['2013-01-01', '2023-05-31']\n",
    "scaling_features = {'rbc' : ['Volume', 'Change', 'ROC', 'ks_ROC'],\n",
    "                    'mmc' : ['Open', 'High', 'Low', 'Close', 'MA_5', 'STD', 'Upper', 'Lower', 'OBV',\n",
    "                              'MA', 'CCI', 'fast_k', 'fast_d', 'RSI', 'MFI', 'MA_10', 'ks_fast']}\n",
    "model_features = ['Volume', 'Change', 'ROC', 'ks_ROC', 'MA_5', 'STD', 'Upper', 'Lower',\n",
    "                  'OBV', 'MA', 'CCI', 'fast_k', 'fast_d', 'RSI', 'MFI', 'MA_10', 'ks_fast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=1000, trials=trials, rstate=np.random.default_rng(42))\n",
    "\n",
    "# 최소화 파라미터 조합 출력\n",
    "print('Best Hyperparameters:')\n",
    "print(best)\n",
    "\n",
    "# 최소화 파라미터를 통해 학습한 모델로 평가\n",
    "model, test_X, test_y = objective(best, eval=True)\n",
    "AUC_ROC(model, test_X, test_y)\n",
    "pred = model.predict(test_X)\n",
    "print('테스트데이터 정확도, 0라벨비율 :', accuracy_score(test_y, pred), 1 - np.round(test_y.sum() / len(test_y), 4))\n",
    "\n",
    "proba = model.predict_proba(test_X)[:, 1]\n",
    "loss = -np.mean(test_y * np.log(proba) + (1 - test_y) * np.log(1 - proba))\n",
    "print('테스트데이터 엔트로피, 1예측확률평균 :', loss, proba.mean())\n",
    "sns.histplot(proba, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribute(trials)\n",
    "show_imp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 trials에 대해 params 분포 보여줌\n",
    "trials_list = [loss_trials, trials, roc_trials]\n",
    "\n",
    "con_params = ['learning_rate', 'gamma', 'reg_lambda', 'reg_alpha', 'subsample', 'colsample_bytree', 'n_estimators', ]\n",
    "int_params = ['max_depth', 'MA', 'CCI', 'fast_k', 'fast_d', 'ROC', 'ks_ROC', 'RSI', 'MFI']\n",
    "\n",
    "num_params_per_row = 3  # 한 줄에 표시할 parameter 수\n",
    "num_rows = len(list(space.keys())) # 총 줄 수\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_params_per_row, figsize=(15, 5*num_rows))\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "for j, t in enumerate(trials_list):\n",
    "    parameters = [trial['misc']['vals'] for trial in t.trials]\n",
    "    for i in range(num_rows):\n",
    "        parameter = list(space.keys())[i]\n",
    "        if parameter in int_params:\n",
    "            parameter_values = t.idxs_vals[1][parameter]\n",
    "            value_range = range(int(min(parameter_values)), int(max(parameter_values))+1)\n",
    "            parameter_counts = [parameter_values.count(i) for i in value_range]\n",
    "\n",
    "            axes[i, j].bar(value_range, parameter_counts)\n",
    "            axes[i, j].set_xlabel(parameter)\n",
    "            axes[i, j].set_ylabel('Counts')\n",
    "            axes[i, j].set_title('Distribution of '+parameter)\n",
    "            axes[i, j].legend()\n",
    "        if parameter in con_params:\n",
    "            parameter_values = t.idxs_vals[1][parameter]\n",
    "            axes[i, j].hist(parameter_values, bins=40)\n",
    "            axes[i, j].set_xlabel(parameter)\n",
    "            axes[i, j].set_ylabel('Counts')\n",
    "            axes[i, j].set_title('Distribution of '+parameter)\n",
    "            axes[i, j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params_per_row = 3  # 한 줄에 표시할 parameter 수\n",
    "num_rows = len(list(space.keys())[8:]) # 총 줄 수\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_params_per_row, figsize=(15, 5*num_rows))\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "for j, t in enumerate(trials_list):\n",
    "    parameters = [trial['misc']['vals'] for trial in t.trials]\n",
    "    for i in range(num_rows):\n",
    "        parameter = list(space.keys())[8:][i]\n",
    "        parameter_values = [int(params[parameter][0]) for params in parameters]\n",
    "        unique_values = np.sort(np.unique(parameter_values))\n",
    "        mean_losses = [np.mean(losses[parameter_values == ma]) for ma in unique_values]\n",
    "        std_losses = [np.std(losses[parameter_values == ma]) for ma in unique_values]\n",
    "            \n",
    "        axes[i, j].plot(unique_values, mean_losses, marker='o', label=f'Trial {j+1}')\n",
    "        axes[i, j].fill_between(unique_values, np.array(mean_losses) - np.array(std_losses),\n",
    "                                    np.array(mean_losses) + np.array(std_losses), alpha=0.2)\n",
    "        \n",
    "        axes[i, j].set_xlabel(parameter)\n",
    "        axes[i, j].set_ylabel('Loss')\n",
    "        axes[i, j].set_title('Mean Loss and Standard Deviation')\n",
    "        axes[i, j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial 횟수 증가에 따른 loss 그려줌\n",
    "fig, axes = plt.subplots(3, 1, figsize=(20, 15))\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "for i, t in enumerate(trials_list):\n",
    "    axes[i].plot(range(len(t.losses())), t.losses(), marker='o', markersize=2)\n",
    "    axes[i].set_xlabel('Try')\n",
    "    axes[i].set_ylabel('Loss')\n",
    "    axes[i].set_title(f'Trial {i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 히트맵\n",
    "model, original_data, train_X, val_X, test_X, train_y, val_y, test_y = result_xgb\n",
    "prob = model.predict_proba(np.concatenate([train_X, val_X, test_X], axis=0))\n",
    "original_data['Score'] = prob[:, 1]\n",
    "# original_data = original_data[original_data.Date > '2017-12-31']\n",
    "\n",
    "df = original_data.iloc[len(original_data)-len(test_y):, :]\n",
    "# df = df[df.Code == '005930']\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "\n",
    "sns.heatmap(df[['Volume', 'ROC', 'ks_ROC', 'CCI', 'fast_k', 'fast_d', 'RSI', 'MFI', 'ks_fast', 'RSI_DP', 'DP', 'ks_DP', 'Out', 'Score', 'label',\n",
    "       'FROC_60', 'FROC_30', 'FROC_10', 'FROC_5'\n",
    "       ]].corr(), ax=ax, annot=True, annot_kws={'size':10}, fmt='.1g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot -> 상관관계 시각화\n",
    "sns.pairplot(df[['CCI', 'fast_k', 'RSI', 'MFI', 'Score', 'RSI_DP', 'DP', 'ks_DP', 'ks_ROC', 'FROC_60', 'FROC_30', 'FROC_10', 'FROC_5']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주가상승률, Score간의 pearsonr 검정\n",
    "name_list = ['FROC_60', 'FROC_30', 'FROC_10', 'FROC_5']\n",
    "for name in name_list:\n",
    "    score_returns_corr, score_returns_pvalue = stats.pearsonr(df['Score'], df[name])\n",
    "    print(f'[{name}, Score] pearsonr({np.round(score_returns_corr, 4)}) p-value : {np.round(score_returns_pvalue, 6)}')\n",
    "\n",
    "for i, name in enumerate(name_list):\n",
    "    sns.jointplot(data=df, x='Score', y=name, kind='reg')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
